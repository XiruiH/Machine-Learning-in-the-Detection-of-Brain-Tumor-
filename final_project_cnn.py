# -*- coding: utf-8 -*-
"""Final Project CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H80vOp885aXmTWwE8d4AHy_YeQGedZFv

# **READ ME**

## **Introduction**
Our project is about applying machine learning and deep learning algorithms that will help in the quick detection of brain tumors. We were able to implement different methods such as Convolution Neural Networks (CNN), Support Vector Machines (SVM), and Random Forests in detecting the presence of brain tumors. The instructions in this readme file will give you information about how to run the program on your local machine.

## **Prerequisite**
Our program was originally created in Google Colab as a Jupyter Notebook (.ipynb), so it runs best in Google Colab. However, with necessary small modifications, it can run in any other environment and across all platforms (Windows, macOS, or Linux). The model is lightweight and uses a small amount of RAM, but the image dataset is 15 MB. Ensure you have enough storage to download and run the program before attempting to do so.

## **Preparation**
Download the Brain Tumor images from Kaggle (15 MB), available here: https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor.
	In the third cell of the program, edit variables img_dataset_path and csv_path to the correct file paths for the image dataset and csv on your machine. If desired, you can also edit the image_height, image_width, and epoch variables to finetune the model.
	The second cell of the program connects to Google Drive. If you are not running the program in Google Colab, you do not need to run this cell.

## **Running the program**
Run each cell in the order they appear. The program first performs all pre-processing steps, then creates the model based on the training set images, then validates the model on the testing set images.

## **Methods used in this project**
Convolution Neural Networks (CNN)
Support Vector Machines (SVM)
Random Forests

## **Acknowledgements**
This model uses the following Brain Tumor images from Kaggle: https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor. The preprocessing code was adapted from [91%]BrainTumorDetection by Shivam Chaudhury on Kaggle: https://www.kaggle.com/code/shivam199/91-braintumordetection. The model code was adapted from BMGT408 CNN_for_fashion-408E-2021.

#Pre-processing
"""

#Pre-processing code adapted from [91%]BrainTumorDetection by Shivam Chaudhury on Kaggle: https://www.kaggle.com/code/shivam199/91-braintumordetection

import pandas as pd
import numpy as np
import os

from sklearn.model_selection import train_test_split
from PIL.Image import open

from google.colab import drive
drive.mount('/content/drive')

#these variables can be adjusted according to the appropriate paths for your system and the desired image height, image width, and epochs
img_dataset_path = "/content/drive/MyDrive/College/5PlusOne/Semester 1/BUDT704 PYTH/BUDT704 final project/Brain Tumor/Brain Tumor"
csv_path = "/content/drive/MyDrive/College/5PlusOne/Semester 1/BUDT704 PYTH/BUDT704 final project/Brain Tumor.csv"
image_height = 28
image_width = 28
epochs = 10

#prepares images to be normalized
cortex_df = pd.read_csv(csv_path)
dataset_df = pd.DataFrame()
dataset_df["Image"] = cortex_df["Image"]
dataset_df["Class"] = cortex_df["Class"]
path_list = []
for img_path in os.listdir(img_dataset_path):
    path_list.append(os.path.join(img_dataset_path,img_path))
path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in path_list}
dataset_df["paths"] = cortex_df["Image"].map(path_dict.get)
dataset_df["pixels"] = dataset_df["paths"].map(lambda x:np.asarray(open(x).resize((image_height,image_width))))

#normalizes pixel values for all images
image_list = []
for i in range(len(dataset_df)):
    brain_image = dataset_df["pixels"][i].astype(np.float32)
    brain_image /= 255
    image_list.append(brain_image)
#splits training and testing sets
X = np.array(image_list)
y = np.array(dataset_df.Class)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

"""#Model"""

#Model code adapted from BMGT408 CNN_for_fashion-408E-2021

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from tensorflow.keras import layers, models
from tensorflow.keras.models import load_model
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from tensorflow.keras.utils import to_categorical

def baseline_model():
    model = Sequential()
    model.add(Conv2D(32,(3,3),padding="SAME",activation="relu",input_shape = (image_height, image_width, 3)))
    model.add(MaxPooling2D(pool_size=(2,2)))
    #the following layers were commented out to reduce overfitting. they may be reimplemented to increase model accuracy, if desired.
    #model.add(Conv2D(64,(3,3),padding="SAME",activation="relu"))
    #model.add(MaxPooling2D(pool_size=(2,2)))
    #model.add(Dropout(0.5))
    #model.add(Conv2D(128,(3,3),padding="SAME",activation="relu"))
    #model.add(MaxPooling2D(pool_size=(2,2)))
    #model.add(Dropout(0.5))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid')) #to indicate binary output 0 or 1
    model.compile(loss='binary_crossentropy', 
                  optimizer='adam', 
                  metrics=['accuracy'])
    return model

model = baseline_model()
model.summary()

history = model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=10)

"""#Validation"""

eval_score = model.evaluate(X_test, y_test)
print("Test loss:", eval_score[0])
print("Test accuracy:", eval_score[1])